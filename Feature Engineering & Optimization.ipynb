{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import time\n",
    "from utils import add_groupby_feats\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_div = 1024**2 # denominator to convert memory usage to readable sizes\n",
    "repeat = 5 # repeat code to get an average of execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "- Original Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_naive = []\n",
    "for cnt in range(repeat):\n",
    "    start = time.time()\n",
    "    prior = pd.read_csv('order_products__prior.csv')\n",
    "    train = pd.read_csv('order_products__train.csv')\n",
    "    orders = pd.read_csv('orders.csv')\n",
    "    time_naive.append(time.time() - start)\n",
    "\n",
    "time_naive = round(np.array(time_naive).mean(), 3)\n",
    "mem_naive = prior.memory_usage().sum() + train.memory_usage().sum() \n",
    "mem_naive += orders.memory_usage().sum()\n",
    "mem_naive = round(mem_naive / mem_div, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimized loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Feat_Eng_Opt.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Feat_Eng_Opt.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def read_csv_with_dtype(path, dtype_dict):\n",
    "    ''' Input params:\n",
    "            path - string, dtype_dict - dictionary\n",
    "        Output:\n",
    "            df - pandas dataframe'''\n",
    "    df = pd.read_csv(path, dtype = dtype_dict)\n",
    "    return df\n",
    "\n",
    "def load_data_opt(repeat = 5, mem_div = 1024**2):\n",
    "    time_opt = []\n",
    "    dtype_dict = {\n",
    "        'order_id': np.uint32, 'product_id': np.uint16, 'add_to_cart_order': np.uint8,\n",
    "        'reordered': np.uint8\n",
    "    }\n",
    "    # parameters to be passed for multiprocessing\n",
    "    load_params = [\n",
    "        ('order_products__prior.csv', dtype_dict), ('order_products__train.csv', dtype_dict),\n",
    "        ('orders.csv', {\n",
    "            'order_id': np.uint32, 'user_id': np.uint32, 'eval_set': 'category',\n",
    "            'order_number': np.uint8, 'order_dow': 'category', 'order_hour_of_day': 'category',\n",
    "            'days_since_prior_order': np.float16})]\n",
    "    \n",
    "    for cnt in range(repeat):\n",
    "        start = time.time()\n",
    "        # multiprocessing with 3 processes\n",
    "        with Pool(3) as p:\n",
    "            dfs = p.starmap(read_csv_with_dtype, load_params)\n",
    "\n",
    "        time_opt.append(time.time() - start)\n",
    "\n",
    "    time_opt = round(np.array(time_opt).mean(), 3)\n",
    "    prior, train, orders = list(dfs)\n",
    "    mem_opt = prior.memory_usage().sum() + train.memory_usage().sum() \n",
    "    mem_opt += orders.memory_usage().sum()\n",
    "    mem_opt = round(mem_opt / mem_div, 3)\n",
    "    return time_opt, mem_opt, dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original average datasets loading time is 10.886 secs.\n",
      "Optimized average datasets loading time is 9.009 secs.\n",
      "\n",
      "Original memory usage of datasets is 1214.783 MBs.\n",
      "Optimized memory usage of datasets is 303.696 MBs.\n"
     ]
    }
   ],
   "source": [
    "from Feat_Eng_Opt import load_data_opt\n",
    "\n",
    "time_opt, mem_opt, dfs_opt = load_data_opt()\n",
    "print(f'Original average datasets loading time is {time_naive} secs.')\n",
    "print(f'Optimized average datasets loading time is {time_opt} secs.\\n')\n",
    "print(f'Original memory usage of datasets is {mem_naive} MBs.')\n",
    "print(f'Optimized memory usage of datasets is {mem_opt} MBs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _user_buy_product_times: how many times have the user bought the product\n",
    "col_user_buy_product_times = '_user_buy_product_times'\n",
    "\n",
    "# aggregation functions to be applied\n",
    "prod_agg = {'user_id': ['count'], 'reordered': ['sum'],\n",
    "            col_user_buy_product_times: [lambda x: sum(x == 1), lambda x: sum(x == 2)]}\n",
    "\n",
    "#_prod_tot_cnts: how many times have this product be bought\n",
    "#_prod_reorder_tot_cnts: how many times have this product be reorderd\n",
    "#_prod_buy_first_time_total_cnt: how many unique users have bought this product\n",
    "#_prod_buy_second_time_total_cnt: how many unique users have reordered this product\n",
    "col_tot_cnts, col_reorder_tot_cnts = '_prod_tot_cnts', '_prod_reorder_tot_cnts'\n",
    "col_buy_first_time_total_cnt = '_prod_buy_first_time_total_cnt'\n",
    "col_buy_second_time_total_cnt = '_prod_buy_second_time_total_cnt'\n",
    "prod_cols = [col_tot_cnts, col_reorder_tot_cnts, col_buy_first_time_total_cnt,\n",
    "             col_buy_second_time_total_cnt]\n",
    "\n",
    "#_prod_reorder_prob: among the users who have bought this product, what percentage of them reordered it\n",
    "#_prod_reorder_ratio: among the products that have been bought, how many of them were reoredred products\n",
    "#_prod_reorder_times: average reorder times among the users who have bought this product\n",
    "col_prod_reorder_prob = '_prod_reorder_prob'\n",
    "col_prod_reorder_ratio = '_prod_reorder_ratio'\n",
    "col_prod_reorder_times = '_prod_reorder_times'\n",
    "\n",
    "prior_opt, train_opt, orders_opt = dfs_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_naive = []\n",
    "for cnt in range(3):\n",
    "    start = time.time()\n",
    "    # add order info to priors\n",
    "    prior_orders = orders.set_index('order_id').join(prior.set_index('order_id'),\n",
    "                                                     how = 'inner')\n",
    "\n",
    "    prior_orders[col_user_buy_product_times] = [p + 1 for p \n",
    "                                                in prior_orders.groupby(['user_id',\n",
    "                                                                         'product_id']).cumcount()]\n",
    "\n",
    "    prod = add_groupby_feats(prior_orders, ['product_id'], prod_agg, prod_cols)\n",
    "    prod[col_prod_reorder_prob] = prod[col_buy_second_time_total_cnt] / prod[col_buy_first_time_total_cnt]\n",
    "    prod[col_prod_reorder_ratio] = prod[col_reorder_tot_cnts] / prod[col_tot_cnts]\n",
    "    prod[col_prod_reorder_times] = 1 + prod[col_reorder_tot_cnts] / prod[col_buy_first_time_total_cnt]\n",
    "    time_naive.append(time.time() - start)\n",
    "\n",
    "time_naive = round(np.array(time_naive).mean(), 3)\n",
    "mem_naive = round(prod.memory_usage().sum() / mem_div, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimized processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Feat_Eng_Opt.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Feat_Eng_Opt.py\n",
    "\n",
    "import time, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from utils import *\n",
    "\n",
    "def prod_feat_opt(df_left, df_right, po_col, prod_agg, prod_new_cols, prod_proc_cols,\n",
    "                  repeat = 5, mem_div = 1024**2):\n",
    "    '''\n",
    "    Input params:\n",
    "        df_left - pandas dataframe, df_right - pandas dataframe, po_col - string,\n",
    "        prod_agg - dictionary, prod_new_cols - list, prod_proc_cols - list\n",
    "    Output:\n",
    "        time_opt - float, mem_opt - float, prod - pandas dataframe\n",
    "    '''\n",
    "    time_opt = []\n",
    "    col_tot, col_reorder, col_1st, col_2nd = prod_new_cols\n",
    "    col_prob, col_ratio, col_times = prod_proc_cols\n",
    "    for cnt in range(repeat):\n",
    "        start = time.time()\n",
    "        # add order info to priors\n",
    "        merge_mul_partial = partial(merge_mul, 'order_id', 'inner', df_left)\n",
    "        cpu_cnt = os.cpu_count()\n",
    "        with Pool(cpu_cnt) as p:\n",
    "            pos = p.map(merge_mul_partial, np.array_split(df_right, cpu_cnt))\n",
    "            \n",
    "        prior_orders = pd.concat(list(pos))\n",
    "        \n",
    "        prior_orders[po_col] = prior_orders.groupby(['user_id', 'product_id']).cumcount() + 1\n",
    "        \n",
    "        prod = add_groupby_feats(prior_orders, ['product_id'], prod_agg, prod_new_cols)\n",
    "        prod[col_prob] = prod[col_2nd] / prod[col_1st]\n",
    "        prod[col_ratio] = prod[col_reorder] / prod[col_tot]\n",
    "        prod[col_times] = 1 + prod[col_reorder] / prod[col_1st]\n",
    "        time_opt.append(time.time() - start)\n",
    "        \n",
    "    time_opt = round(np.array(time_opt).mean(), 3)\n",
    "    # optimize memory usage\n",
    "    prod[['product_id', col_2nd]] = prod[['product_id', col_2nd]].apply(np.uint16)\n",
    "    prod[[col_tot, col_1st]] = prod[[col_tot, col_1st]].apply(np.uint32)\n",
    "    prod[prod.select_dtypes(np.float64).columns] = prod.select_dtypes(np.float64).astype(np.float16)\n",
    "    \n",
    "    mem_opt = round(prod.memory_usage().sum() / mem_div, 3)\n",
    "    return time_opt, mem_opt, prod, prior_orders\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Feat_Eng_Opt import prod_feat_opt\n",
    "\n",
    "time_opt, mem_opt, prod_opt, prior_orders_opt = prod_feat_opt(prior_opt, orders_opt,\n",
    "                                                              col_user_buy_product_times,\n",
    "                                                              prod_agg, prod_cols,\n",
    "                                                              [col_prod_reorder_prob,\n",
    "                                                               col_prod_reorder_ratio,\n",
    "                                                               col_prod_reorder_times], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original average product features processing time is 79.381 secs.\n",
      "Optimized average product features processing time is 61.231 secs.\n",
      "\n",
      "Original memory usage of newly generated product features is 3.032 MBs.\n",
      "Optimized memory usage of newly generated product features is 0.948 MBs.\n"
     ]
    }
   ],
   "source": [
    "print(f'Original average product features processing time is {time_naive} secs.')\n",
    "print(f'Optimized average product features processing time is {time_opt} secs.\\n')\n",
    "print(f'Original memory usage of newly generated product features is {mem_naive} MBs.')\n",
    "print(f'Optimized memory usage of newly generated product features is {mem_opt} MBs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "\n",
    "# _user_total_orders: how many orders have the user placed in the prior dataset\n",
    "# _user_sum_days_since_prior_order: sum of days since prior order\n",
    "# _user_mean_days_since_prior_order: average number of days since prior order\n",
    "col_user_order_cnt = '_user_total_orders'\n",
    "user_cols = [col_user_order_cnt, '_user_sum_days_since_prior_order',\n",
    "             '_user_mean_days_since_prior_order']\n",
    "\n",
    "# aggregation functions to be applied\n",
    "user_agg_1 = {'order_number': ['max'], 'days_since_prior_order': ['sum', 'mean']}\n",
    "\n",
    "user_agg_2 = {'reordered': ['sum'], 'product_id': ['count', lambda x: x.nunique()],\n",
    "              'order_number': [lambda x: sum(x > 1)]}\n",
    "\n",
    "# _user_reorder_ratio: number of reorders / number of orders after 1st order\n",
    "# _user_total_products: number of products the user has bought\n",
    "# _user_distinct_products: number of unique products the user has bought\n",
    "col_user_reorder_ratio = '_user_reorder_ratio'\n",
    "col_user_total_products = '_user_total_products'\n",
    "col_user_distinct_products = '_user_distinct_products'\n",
    "\n",
    "col_reorder_sum = 'reordered_sum'\n",
    "user_cols_2 = [col_reorder_sum, col_user_total_products, col_user_distinct_products,\n",
    "               'order_number']\n",
    "\n",
    "# _user_average_basket: average number of products per order for this user\n",
    "col_user_average_basket = '_user_average_basket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_naive = []\n",
    "for cnt in range(repeat):\n",
    "    start = time.time()\n",
    "    user1 = add_groupby_feats(orders[orders['eval_set'] == 'prior'].copy(), ['user_id'],\n",
    "                              user_agg_1, user_cols)\n",
    "\n",
    "    user2 = add_groupby_feats(prior_orders, ['user_id'], user_agg_2, user_cols_2)\n",
    "    user2[col_user_reorder_ratio] = user2[col_reorder_sum] / user2['order_number']\n",
    "    user2.drop([col_reorder_sum, 'order_number'], axis = 1, inplace = True)\n",
    "    users = user1.merge(user2, how = 'inner')\n",
    "    users[col_user_average_basket] = users[col_user_total_products] / users[col_user_order_cnt]\n",
    "    user3 = orders[orders['eval_set'] != \"prior\"][['user_id', 'order_id', 'eval_set',\n",
    "                                                   'days_since_prior_order']]\n",
    "\n",
    "    user3.rename(index = str, columns = {'days_since_prior_order': 'time_since_last_order'},\n",
    "                 inplace = True)\n",
    "\n",
    "    users = users.merge(user3, how='inner')\n",
    "\n",
    "    time_naive.append(time.time() - start)\n",
    "    \n",
    "time_naive = round(np.array(time_naive).mean(), 3)\n",
    "del user1, user2, user3\n",
    "mem_naive = round(users.memory_usage().sum() / mem_div, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimized processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Feat_Eng_Opt.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Feat_Eng_Opt.py\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from utils import *\n",
    "from functools import partial\n",
    "import os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def df_larger_sub(col, val, df):\n",
    "    '''\n",
    "    Input params:\n",
    "        df - pandas dataframe, col - string, val - int\n",
    "    Output:\n",
    "        df_sub - pandas dataframe\n",
    "    '''\n",
    "    df_sub = df[df[col] > val]\n",
    "    return df_sub\n",
    "\n",
    "def merge_idx(df_left, df_right):\n",
    "    '''\n",
    "    Input params:\n",
    "        df_left - pandas dataframe, df_right - pandas dataframe\n",
    "    Output:\n",
    "        df - pandas dataframe\n",
    "    '''\n",
    "    df = df_left.merge(df_right, how = 'inner', left_index = True, right_index = True)\n",
    "    return df\n",
    "\n",
    "def user_feat_opt(df1, df2, df2_cols, col_add, col_reorder, col_users, repeat = 5,\n",
    "                  mem_div = 1024**2):\n",
    "    \n",
    "    '''\n",
    "    Input params:\n",
    "        df1 - pandas dataframe, df2 - pandas dataframe, df_cols - list, col - string\n",
    "    Output:\n",
    "        time_opt - float, mem_opt - float, users - pandas dataframe\n",
    "    '''\n",
    "    time_opt = []\n",
    "    # aggregation functions to be applied\n",
    "    user_agg_1 = {'order_number': ['max'], 'days_since_prior_order': ['sum', 'mean']}    \n",
    "    user_agg_2 = {'reordered': ['sum'], 'product_id': ['count', 'nunique']}\n",
    "    \n",
    "    df1_prior = df1[df1['eval_set'] == 'prior']\n",
    "    df1_non_prior = df1[df1['eval_set'] != \"prior\"][['user_id', 'order_id', 'eval_set',\n",
    "                                                     'days_since_prior_order']]\n",
    "    \n",
    "    df1_non_prior.rename(index = str, columns = {'days_since_prior_order':\n",
    "                                                 'time_since_last_order'}, inplace = True)\n",
    "    \n",
    "    for cnt in range(repeat):\n",
    "        start = time.time()\n",
    "        user1 = add_groupby_feats(df1_prior, ['user_id'], user_agg_1, col_users)\n",
    "        user21 = add_groupby_feats(df2, ['user_id'], user_agg_2,\n",
    "                                   [col_reorder] + df2_cols).set_index('user_id')\n",
    "        \n",
    "        cpu_cnt = os.cpu_count()\n",
    "        df_larger_sub_partial = partial(df_larger_sub, 'order_number', 1)\n",
    "        # multiprocessing\n",
    "        with Pool(cpu_cnt) as p:\n",
    "            d = p.map(df_larger_sub_partial, np.array_split(df2, cpu_cnt))\n",
    "            \n",
    "        df3 = pd.concat(list(d))\n",
    "        user22 = df3.groupby(['user_id']).agg({'order_number': 'count'})\n",
    "        merge_partial = partial(merge_idx, user21)\n",
    "        # multiprocessing\n",
    "        with Pool(cpu_cnt) as p:\n",
    "            d = p.map(merge_partial, np.array_split(user22, cpu_cnt))\n",
    "            \n",
    "        user2 = pd.concat(list(d))\n",
    "        user2[col_add] = user2[col_reorder] / user2['order_number']\n",
    "        user2.drop([col_reorder, 'order_number'], axis = 1, inplace = True)\n",
    "        user2.reset_index(inplace = True)\n",
    "        del user21, user22\n",
    "        u1, u2 = user1.set_index('user_id'), user2.set_index('user_id')\n",
    "        join_mul_partial = partial(join_mul, u1)\n",
    "        # multiprocessing\n",
    "        with Pool(cpu_cnt) as p:\n",
    "            d = p.map(join_mul_partial, np.array_split(u2, cpu_cnt))\n",
    "            \n",
    "        users = pd.concat(list(d))\n",
    "        u2 = df1_non_prior.set_index('user_id')\n",
    "        join_mul_partial = partial(join_mul, users)\n",
    "        # multiprocessing\n",
    "        with Pool(cpu_cnt) as p:\n",
    "            d = p.map(join_mul_partial, np.array_split(u2, cpu_cnt))\n",
    "            \n",
    "        users = pd.concat(list(d)).reset_index()\n",
    "        time_opt.append(time.time() - start)\n",
    "        \n",
    "    time_opt = round(np.array(time_opt).mean(), 3)\n",
    "    # memory usage optimization\n",
    "    users[df2_cols] = users[df2_cols].apply(np.uint16)\n",
    "    users[users.select_dtypes(np.float64).columns] = users.select_dtypes(np.float64).astype(np.float16)\n",
    "    \n",
    "    mem_opt = round(users.memory_usage().sum() / mem_div, 3)\n",
    "    return time_opt, mem_opt, users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Feat_Eng_Opt import user_feat_opt\n",
    "\n",
    "time_opt, mem_opt, users_opt = user_feat_opt(orders_opt, prior_orders_opt,\n",
    "                                             [col_user_total_products,\n",
    "                                              col_user_distinct_products],\n",
    "                                             col_user_reorder_ratio, col_reorder_sum,\n",
    "                                             user_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original average product features processing time is 53.64 secs.\n",
      "Optimized average product features processing time is 33.602 secs.\n",
      "\n",
      "Original memory usage of newly generated product features is 18.879 MBs.\n",
      "Optimized memory usage of newly generated product features is 5.113 MBs.\n"
     ]
    }
   ],
   "source": [
    "print(f'Original average product features processing time is {time_naive} secs.')\n",
    "print(f'Optimized average product features processing time is {time_opt} secs.\\n')\n",
    "print(f'Original memory usage of newly generated product features is {mem_naive} MBs.')\n",
    "print(f'Optimized memory usage of newly generated product features is {mem_opt} MBs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User - Product Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _up_order_count: number of times the user has purchased this product\n",
    "# _up_first_order_number: order number when the user first purchased this product\n",
    "# _up_last_order_number: order number when the user last purchased this product\n",
    "# _up_average_cart_position: the product's average position in cart of this user\n",
    "col_up_order_count = '_up_order_count'\n",
    "col_user_prod_1st_order_num = '_up_first_order_number'\n",
    "col_user_prod_last_order_num = '_up_last_order_number'\n",
    "\n",
    "# _up_order_rate: (number of times the product has been bought by user) / number of orders of the user\n",
    "# _up_order_since_last_order: (most recent order number of the user) - (most recent order number containing the product)\n",
    "# _up_order_rate_since_first_order: (number of times that the user has bought this product) / (number of orders within this purchasing history framework)\n",
    "col_rate = '_up_order_rate'\n",
    "col_since_last = '_up_order_since_last_order'\n",
    "col_since_1st ='_up_order_rate_since_first_order'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Original processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_naive = []\n",
    "for cnt in range(3):\n",
    "    start = time.time()\n",
    "    data = add_groupby_feats(prior_orders, ['user_id', 'product_id'],\n",
    "                             {'order_number': ['count', 'min', 'max'],\n",
    "                              'add_to_cart_order': ['mean']}, [col_up_order_count,\n",
    "                                                               col_user_prod_1st_order_num,\n",
    "                                                               col_user_prod_last_order_num,\n",
    "                                                               '_up_average_cart_position'])\n",
    "    \n",
    "    data = prod.merge(data, how = 'inner', on = 'product_id').merge(users, how = 'inner',\n",
    "                                                                    on = 'user_id')\n",
    "    \n",
    "    data[col_rate] = data[col_up_order_count] / data[col_user_order_cnt]\n",
    "    data[col_since_last] = data[col_user_order_cnt] - data[col_user_prod_last_order_num]\n",
    "    data[col_since_1st] = data[col_up_order_count] / (data[col_user_order_cnt] - data[col_user_prod_1st_order_num] + 1)\n",
    "    train_orders = orders[['order_id',\n",
    "                           'user_id']].set_index('order_id').join(train.set_index('order_id'),\n",
    "                                                                  how = 'right')\n",
    "    \n",
    "    data = data.set_index(['user_id',\n",
    "                           'product_id']).join(train_orders[['user_id', 'product_id',\n",
    "                                                             'reordered']].set_index(['user_id',\n",
    "                                                                                     'product_id']),\n",
    "                                               how = 'left')\n",
    "    \n",
    "    time_naive.append(time.time() - start)\n",
    "    \n",
    "time_naive = round(np.array(time_naive).mean(), 3)\n",
    "mem_naive = round(data.memory_usage().sum() / mem_div, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optimized processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_naive = []\n",
    "for cnt in range(3):\n",
    "    start = time.time()\n",
    "    data_opt = add_groupby_feats(prior_orders_opt, ['user_id', 'product_id'],\n",
    "                                 {'order_number': ['count', 'min', 'max'],\n",
    "                                  'add_to_cart_order': ['mean']},\n",
    "                                 [col_up_order_count, col_user_prod_1st_order_num,\n",
    "                                  col_user_prod_last_order_num, '_up_average_cart_position'])\n",
    "    \n",
    "    d, p = data_opt.set_index('product_id'), prod_opt.set_index('product_id')\n",
    "    u = users_opt.set_index('user_id')\n",
    "    data_opt = d.join(p, how = 'inner').reset_index().set_index('user_id').join(u, how = 'inner').reset_index()\n",
    "    \n",
    "    data_opt[col_rate] = data_opt[col_up_order_count] / data_opt[col_user_order_cnt]\n",
    "    data_opt[col_since_last] = data_opt[col_user_order_cnt] - data_opt[col_user_prod_last_order_num]\n",
    "    data_opt[col_since_1st] = data_opt[col_up_order_count] / (data_opt[col_user_order_cnt] - data_opt[col_user_prod_1st_order_num] + 1)\n",
    "    train_orders_opt = train_opt.merge(orders_opt[['order_id', 'user_id']], how = 'left',\n",
    "                                       on = 'order_id')\n",
    "    \n",
    "    data_opt = data_opt.merge(train_orders_opt[['user_id', 'product_id', 'reordered']],\n",
    "                              how = 'left', on = ['user_id', 'product_id'])\n",
    "    \n",
    "    time_naive.append(time.time() - start)\n",
    "    \n",
    "time_naive = round(np.array(time_naive).mean(), 3)\n",
    "mem_naive = round(data_opt.memory_usage().sum() / mem_div, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original average product features processing time is 42.932 secs.\n",
      "Optimized average product features processing time is 33.602 secs.\n",
      "\n",
      "Original memory usage of newly generated product features is 1307.22 MBs.\n",
      "Optimized memory usage of newly generated product features is 5.113 MBs.\n"
     ]
    }
   ],
   "source": [
    "print(f'Original average product features processing time is {time_naive} secs.')\n",
    "print(f'Optimized average product features processing time is {time_opt} secs.\\n')\n",
    "print(f'Original memory usage of newly generated product features is {mem_naive} MBs.')\n",
    "print(f'Optimized memory usage of newly generated product features is {mem_opt} MBs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
